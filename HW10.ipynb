{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1b57d9",
   "metadata": {},
   "source": [
    "## question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4389d9",
   "metadata": {},
   "source": [
    "1. **Simple vs Multiple Linear Regression**:\n",
    "   - **Simple Linear Regression** models the relationship between one predictor and the outcome.\n",
    "   - **Multiple Linear Regression** includes multiple predictors, capturing more complex relationships. It provides better insights into how several variables influence the outcome.\n",
    "\n",
    "2. **Continuous vs Indicator Variables**:\n",
    "   - **Continuous variables** take any value (e.g., age), while **indicator variables** represent categories with binary values (e.g., gender: 0 = male, 1 = female).\n",
    "   - Simple regression with continuous: `y = β0 + β1x`. With an indicator: `y = β0 + β1D`.\n",
    "\n",
    "3. **Adding Indicator Variable in Multiple Regression**:\n",
    "   - Introducing an indicator alongside a continuous variable helps the model capture category-specific effects (e.g., how age impacts males vs. females).\n",
    "   - Changes the form to: `y = β0 + β1x + β2D`.\n",
    "\n",
    "4. **Interaction Between Continuous and Indicator Variables**:\n",
    "   - Adding an **interaction** models how the relationship between a continuous variable (e.g., age) differs across categories (e.g., gender).\n",
    "   - The form becomes: `y = β0 + β1x + β2D + β3x*D`.\n",
    "\n",
    "5. **Regression with Only Indicator Variables**:\n",
    "   - Using only indicator variables models the effect of categories on the outcome.\n",
    "   - The form is: `y = β0 + β1D1 + β2D2 + ...`, with binary encoding for each category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db669fb",
   "metadata": {},
   "source": [
    "## question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a85db5",
   "metadata": {},
   "source": [
    "The apparent contradiction between the statements \"the model only explains 17.6% of the variability in the data\" and \"many of the coefficients are larger than 10 while having strong or very strong evidence against the null hypothesis of 'no effect'\" arises from the distinction between overall model fit and the statistical significance of individual predictors. When we say that the model explains only 17.6% of the variability in the data, we are referencing the \\( R^2 \\) value, which indicates the proportion of the variation in the dependent variable \\( Y \\) that can be explained by the predictor variables in the model. An \\( R^2 \\) of 0.176, or 17.6%, suggests that a large portion of the variability in \\( Y \\)—82.4% in this case—remains unexplained by the predictors in the model. This could be due to the absence of other influential variables, random noise, or other factors that the current model does not capture.\n",
    "\n",
    "On the other hand, the fact that many coefficients are large (greater than 10) and statistically significant shows that these predictors have a detectable and meaningful impact on \\( Y \\) when considered individually. Strong evidence against the null hypothesis of \"no effect\" for these predictors means that the data provides clear support that these variables influence \\( Y \\) in a consistent way, and the size of the coefficients implies that these impacts are substantial. However, these large and significant individual effects do not necessarily translate into a high \\( R^2 \\) for the model as a whole. This can happen when each predictor impacts \\( Y \\) in a measurable way, but the combination of predictors does not capture enough of the overall variability in \\( Y \\), perhaps because other key factors or interactions are missing from the model. Thus, while the predictors included in the model significantly affect \\( Y \\), they only account for a modest share of its total variability, which is why the model’s \\( R^2 \\) remains low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b6ced",
   "metadata": {},
   "source": [
    "## question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50acfe",
   "metadata": {},
   "source": [
    "The development of these models follows a process of refinement and feature selection to improve predictive accuracy and address multicollinearity issues.\n",
    "\n",
    "1. **Model 5**: Builds on previous models by incorporating main predictors like `Attack`, `Defense`, and `Speed`, and adds categorical indicators for `Generation`, `Type 1`, and `Type 2`. This broad inclusion of variables allows for a more complex initial model.\n",
    "  \n",
    "2. **Model 6**: Refines Model 5 by retaining only significant predictors and adding specific indicators for `Type 1` categories (`Normal`, `Water`) and `Generation` categories (`2`, `5`). This reduces unnecessary variables and improves the interpretability and relevance of predictors.\n",
    "  \n",
    "3. **Model 7**: Adds interaction terms among continuous variables (e.g., `Attack * Speed * Sp. Def * Sp. Atk`), capturing how these features jointly influence `HP`. The centered and scaled version of Model 7 further reduces multicollinearity by standardizing continuous predictors, which notably lowers the condition number (from 2,340,000,000 to 15.4), making the model more stable and interpretable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd7652d",
   "metadata": {},
   "source": [
    "## question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8fc0a",
   "metadata": {},
   "source": [
    "The example involves training several linear regression models on different groups of Pokémon data and checking how well they predict HP values, both for the data they were trained on (in-sample) and for new data (out-of-sample). Here's a summary:\n",
    "\n",
    "1. **Model 7 with Generation 1 Data**:\n",
    "   - Trained on Pokémon from Generation 1.\n",
    "   - In-sample \\( R^2 \\) shows how well the model fits Generation 1 data.\n",
    "   - Out-of-sample \\( R^2 \\) tests how well it predicts Pokémon from other generations (not Generation 1).\n",
    "\n",
    "2. **Model 7 with Generations 1-5 Data**:\n",
    "   - Trained on Pokémon excluding Generation 6.\n",
    "   - It tests how well this model can predict HP values for Generation 6 Pokémon.\n",
    "\n",
    "3. **Model 6 with Generation 1 Data**:\n",
    "   - Similar to Model 7, but with a different set of features.\n",
    "   - It checks in-sample and out-of-sample predictions for Generation 1 and other generations.\n",
    "\n",
    "### Key Points:\n",
    "- **In-sample \\( R^2 \\)**: Measures how well the model fits the training data.\n",
    "- **Out-of-sample \\( R^2 \\)**: Tests how well the model predicts new, unseen data.\n",
    "- **Generations as Subsets**: Models are trained on specific generations, and their predictions are tested on Pokémon from other generations to see how well they generalize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff5f9fb",
   "metadata": {},
   "source": [
    "chatbox link: https://chatgpt.com/share/6736432c-6b58-8002-84eb-10eece22d72e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
